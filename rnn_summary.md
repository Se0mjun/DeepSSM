# π” Recurrent Neural Network (RNN) μ •λ¦¬

## π“ μ •μ
- μ‹ν€€μ¤(Sequence) λ°μ΄ν„°λ¥Ό μ²λ¦¬ν•λ” **μν™ κµ¬μ΅°μ μ‹ κ²½λ§**
- μ΄μ „ μ‹μ μ hidden stateλ¥Ό μ‚¬μ©ν•μ—¬ **μ‹κ°„μ μΌλ΅ μ—°μ†λ λ°μ΄ν„°μ ν¨ν„΄μ„ ν•™μµ**

## π§  κΈ°λ³Έ μμ‹

$$
\begin{aligned}
h_t &= \tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h) \\
o_t &= W_{ho} h_t + b_o
\end{aligned}
$$

| κΈ°νΈ | μλ―Έ |
|------|------|
| $x_t$ | μ…λ ¥ (at time t) |
| $h_t$ | hidden state |
| $o_t$ | μ¶λ ¥ |
| $W_{xh}$ | μ…λ ¥ β†’ hidden κ°€μ¤‘μΉ |
| $W_{hh}$ | hidden β†’ hidden κ°€μ¤‘μΉ |
| $W_{ho}$ | hidden β†’ output κ°€μ¤‘μΉ |
| $b_h$, $b_o$ | νΈν–¥ (bias) |
| $	anh$ | ν™μ„±ν™” ν•¨μ (λΉ„μ„ ν•μ„± λ¶€μ—¬) |

## π§® ν›λ ¨ κ°€λ¥ν• νλΌλ―Έν„°

| νλΌλ―Έν„° | ν¬κΈ° | μ„¤λ… |
|----------|------|------|
| $W_{xh}$ | $H \times D$ | μ…λ ¥ β†’ hidden λ³€ν™ |
| $W_{hh}$ | $H \times H$ | μν™ μ—°κ²° (μ΄μ „ hidden β†’ ν„μ¬ hidden) |
| $W_{ho}$ | $O \times H$ | hidden β†’ μ¶λ ¥ (optional) |
| $b_h$ | $H$ | hidden bias |
| $b_o$ | $O$ | output bias (optional) |

- $D$: μ…λ ¥ μ°¨μ›  
- $H$: hidden state μ°¨μ›  
- $O$: μ¶λ ¥ μ°¨μ›  

β… μ΄ λ¨λ“  νλΌλ―Έν„°λ” **trainable = True**λ΅ μ„¤μ •λμ–΄ ν•™μµλ¨

## β ν›λ ¨ λ¶κ°€λ¥ν• νλΌλ―Έν„° (Non-trainable)

| ν•­λ© | μ„¤λ… |
|------|------|
| ν•μ΄νΌνλΌλ―Έν„° | hidden size, learning rate, layer μ λ“± |
| μ΄κΈ° μƒνƒ $h_0$ | λ³΄ν†µ 0μΌλ΅ κ³ μ •λλ©° ν•™μµλμ§€ μ•μ |
| μ…λ ¥ λ°μ΄ν„° $x_t$ | ν•™μµμ λ€μƒμ΄ μ•„λ‹λΌ μ΅°κ±΄ |
| dropout λΉ„μ¨ λ“± | λ¨λΈ μ™Έλ¶€ μ„¤μ •κ°’ (ν•™μµλμ§€ μ•μ) |

## π” ν™μ„±ν™” ν•¨μ

- κΈ°λ³Έ RNNμ€ **$\tanh$** ν•¨μλ¥Ό μ‚¬μ©
- μ΄μ :  
  - μ¶λ ¥ λ²”μ„κ°€ $[-1, 1]$ β†’ **zero-centered**
  - ν•™μµ μ•μ •μ„± β†‘
- ReLUλ” μ μ‚¬μ©λμ§€ μ•μ (gradient vanish λ¬Έμ  μ μ§€λ§ memory μ μ§€μ— λ¶€μ ν•©)

## β… νΉμ§• μ”μ•½

| ν•­λ© | μ„¤λ… |
|------|------|
| μ¥μ  | μ‹ν€€μ¤ κΈ°λ° μ…λ ¥ μ²λ¦¬, μ‹κ°„μ  λ§¥λ½ λ°μ |
| λ‹¨μ  | κΈ΄ μ‹ν€€μ¤μ—μ„ gradient vanishing/exploding λ¬Έμ  |
| μ‘μ© | μμ—°μ–΄ μ²λ¦¬, μμ„± μΈμ‹, μ‹κ³„μ—΄ μμΈ΅ λ“± |
